require(kableExtra)
require(tibble)
rmarkdown::render('Predictive.Rmd',output_file='PredictiveSols.pdf')
rmarkdown::render('Predictive.Rmd',output_file='Precitive.pdf')
rmarkdown::render('Predictive.Rmd',output_file='Precitive.pdf')
rmarkdown::render('Predictive.Rmd',output_file='Predictive.pdf')
rmarkdown::render('Predictive.Rmd',output_file='Predictive.pdf')
rmarkdown::render('Predictive.Rmd',output_file='Predictive.pdf')
rmarkdown::render('Predictive.Rmd',output_file='PredictiveSols.pdf')
rmarkdown::render('Predictive.Rmd',output_file='PredictiveSols.pdf')
rmarkdown::render('Predictive.Rmd',output_file='Predictive.pdf')
rmarkdown::render('Predictive.Rmd',output_file='Predictive.pdf')
rmarkdown::render('Predictive.Rmd',output_file='PredictiveSols.pdf')
rmarkdown::render('Predictive.Rmd',output_file='PredictiveSols.pdf')
ExistingWines <- readRDS("~/Documents/Teaching/DataVizA2019/Tutorials/08PredictiveAnalytics/ExistingWines.rds")
rmarkdown::render('Predictive.Rmd',output_file='PredictiveSols.pdf')
if(sols) "*The specificity is the proportion of observations that are truly negative that are classified as negative.*"
rmarkdown::render('Predictive.Rmd',output_file='Predictive.pdf')
Credit_sub <- readRDS("~/Documents/Teaching/DataVizA2019/Lectures/08PredictiveAnalytics/Credit_sub.rds")
rm(list=ls())
ExistingWines
ExistingWines <- readRDS("~/Documents/Teaching/DataVizA2019/Tutorials/09kNN/ExistingWines.rds")
ExistingWines%>%head
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
yhat_k1<-knn(train_x,test_x,train_y,k=1)
train_x<-select(ExistingWines,-BestMarket)
train_y<-select(ExistingWines,BestMarket)
test_x<-readRDS('NewWines.rds')
yhat_k1<-knn(train_x,test_x,train_y,k=1)
?knn
#rmarkdown::render('kNN.Rmd',output_file='kNN.pdf')
#rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
sols<-TRUE
title<-ifelse(sols, 'DataVizA Tutorial: k Nearest Neighbour Classification: Solutions','DataVizA Tutorial: k Nearest Neighbour Classification')
#Use tidyverse
library(dplyr)
library(class)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
train_x<-select(ExistingWines,-BestMarket)
train_y<-pull(ExistingWines,BestMarket)
test_x<-readRDS('NewWines.rds')
yhat_k1<-knn(train_x,test_x,train_y,k=1)
yhat_k1
yhat_k1<-knn(train_x,test_x,train_y,k=11)
yhat_k1
readRDS('Test_y.rds')
test_x%>%sample_n(53)
sample(1:53,53,replace=F)->ind
ind
test_x[ind,]%>%View
View(train_x)
test_x[ind,]%>%saveRDS('NewWines.rds')
readRDS('Test_y.rds')->a
a
a[ind]%>%saveRDS('Test_y.rds')
readRDS('Test_y.rds')
readRDS('NewWines.rds')
test_x[ind,]
readRDS('NewWines.rds')
yhat_k1
readRDS('Test_y.rds')
ind
test_x[ind,]%>%View
test_x%>%View
rm(list=ls())
yhat_k21
#rmarkdown::render('kNN.Rmd',output_file='kNN.pdf')
#rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
sols<-TRUE
title<-ifelse(sols, 'DataVizA Tutorial: k Nearest Neighbour Classification: Solutions','DataVizA Tutorial: k Nearest Neighbour Classification')
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
#Use tidyverse
library(dplyr)
library(class)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
train_x<-select(ExistingWines,-BestMarket)
train_y<-pull(ExistingWines,BestMarket)
test_x<-readRDS('NewWines.rds')
yhat_k1<-knn(train_x,test_x,train_y,k=1)
#The first five predictions can be checked using the head function
head(yhat_k1,5)
yhat_k21<-knn(train_x,test_x,train_y,k=21)
head(yhat_k21,5)
head(yhat_k21,10)
yhat_k21<-knn(train_x,test_x,train_y,k=1)
head(yhat_k21,10)
yhat_k1
test_x
test_x[ind,]
ind<-sample(1:53,53,replace = F)
ind
test_x[ind,]
runif(125)>0.7
ind<-ifelse(runif(125)<0.7,"Training Sample","Test Sample")
ind
#rmarkdown::render('kNN.Rmd',output_file='kNN.pdf')
#rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
sols<-TRUE
title<-ifelse(sols, 'DataVizA Tutorial: k Nearest Neighbour Classification: Solutions','DataVizA Tutorial: k Nearest Neighbour Classification')
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
#Use tidyverse
library(dplyr)
library(class)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
old_x<-select(ExistingWines,-BestMarket)
old_y<-pull(ExistingWines,BestMarket)
new_x<-readRDS('NewWines.rds')
yhat_k1<-knn(old_x,new_x,old_y,k=1)
#The first five predictions can be checked using the head function
head(yhat_k1,5)
yhat_k11<-knn(old_x,new_x,old_y,k=11)
head(yhat_k11,5)
#Create an indicator that determines whether it is training or test sample.
ind<-ifelse(runif(125)<0.7,"Training Sample","Test Sample")
train_y<-old_y[ind=="Training Sample"]
test_y<-old_y[ind=="Test Sample"]
train_x<-old_x[ind=="Training Sample",]
test_x<-old_x[ind=="Test Sample",]
85/125
#rmarkdown::render('kNN.Rmd',output_file='kNN.pdf')
#rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
sols<-TRUE
title<-ifelse(sols, 'DataVizA Tutorial: k Nearest Neighbour Classification: Solutions','DataVizA Tutorial: k Nearest Neighbour Classification')
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
#Use tidyverse
library(dplyr)
library(class)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
old_x<-select(ExistingWines,-BestMarket)
old_y<-pull(ExistingWines,BestMarket)
new_x<-readRDS('NewWines.rds')
yhat_k1<-knn(old_x,new_x,old_y,k=1)
#The first five predictions can be checked using the head function
head(yhat_k1,5)
yhat_k11<-knn(old_x,new_x,old_y,k=11)
head(yhat_k11,5)
#Create an indicator that determines whether it is training or test sample.
ind<-ifelse(runif(125)<0.7,"Training Sample","Test Sample")
train_y<-old_y[ind=="Training Sample"]
test_y<-old_y[ind=="Test Sample"]
train_x<-old_x[ind=="Training Sample",]
test_x<-old_x[ind=="Test Sample",]
yhat_k1<-knn(train_x,test_x,train_y,k=1)
mean(yhat_k1!=test_y)
yhat_k11<-knn(train_x,test_x,train_y,k=11)
mean(yhat_k11!=test_y)
yhat_k1
train_y
test_y
yhat_k1
attr(yhat_k11,"prob")
yhat_k11<-knn(old_x,new_x,old_y,k=11,prob = T)
head(attr(yhat_k11,"prob"),5)
attr(yhat_k11,"prob")
yhat_k1
#Use tidyverse
library(dplyr)
library(class)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
#Split x and y variables
old_x<-select(ExistingWines,-BestMarket)
old_y<-pull(ExistingWines,BestMarket)
#Load in New Wine Data
new_x<-readRDS('NewWines.rds')
yhat_k1<-knn(old_x,new_x,old_y,k=1)
yhat_k1
readRDS('NewWines.rds')%>%sample_n(53,replace = F)
readRDS('NewWines.rds')
rm(list=ls())
setwd("~/Documents/Teaching/DataVizA2019/Tutorials/09kNN")
rm(list=ls())
library(tidyverse)
read_csv('wine.data')->w
w
read_csv('wine.data',col_names = header)->w
source('~/.active-rstudio-document', echo=TRUE)
w
mutate(BestMarket=factor(BestMarket,levels = c('Australia','Europe','Japan')))
mutate(w,BestMarket=factor(BestMarket,levels = c('Australia','Europe','Japan')))
mutate(w,BestMarket=as.factor(BestMarket,levels = c('Australia','Europe','Japan')))
mutate(w,BestMarket=factor(BestMarket,labels = c('Australia','Europe','Japan')))
add_rownames(w,var = 'ID')->wwn
rownames_to_column(w,var = 'ID')->wwn
wwn
old<-sample_frac(wwn,size = 0.7)
ol
old
new<-anti_join(wwn,by="ID")
old<-sample_frac(wwn,size = 0.7)
new<-anti_join(wwn,old,by="ID")
View(new)
View(old)
source('~/.active-rstudio-document', echo=TRUE)
View(newr)
select(old,-ID)
source('~/.active-rstudio-document', echo=TRUE)
pull(new,BestMarket)%>%saveRDS('Test_y.rds')
source('~/.active-rstudio-document', echo=TRUE)
old<-sample_frac(wwn,size = 0.7)
source('~/.active-rstudio-document', echo=TRUE)
NewWines <- readRDS("~/Documents/Teaching/DataVizA2019/Tutorials/09kNN/NewWines.rds")
ExistingWines <- readRDS("~/Documents/Teaching/DataVizA2019/Tutorials/09kNN/ExistingWines.rds")
ExistingWines
source('~/.active-rstudio-document', echo=TRUE)
read_csv('wine.data',col_names = header)%>%
mutate(w,BestMarket=factor(BestMarket,labels = c('Australia','Europe','Japan')))->w
source('~/.active-rstudio-document', echo=TRUE)
#The first ten predictions can be checked using the tail function
tail(yhat_k1,10)
#Create an indicator that determines whether it is training or test sample.
ind<-ifelse(runif(125)<0.7,"Training Sample","Test Sample")
train_y<-old_y[ind=="Training Sample"]
rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
rmarkdown::render('kNN.Rmd',output_file='kNN.pdf')
library(MASS)
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
#Use MASS package
library(MASS)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
#Load in New Wine Data
NewWines<-readRDS('NewWines.rds')
View(ExistingWines)
ldaout<-lda(BestMarket~.,data = ExistingWines)
ldaout
View(ExistingWines)
yhat<-predict(ldaout,newdata = NewWines)
head(yhat,10)
head(yhat$class,10)
#rmarkdown::render('DA.Rmd',output_file='DA.pdf')
#rmarkdown::render('DA.Rmd',output_file='DASols.pdf')
sols<-TRUE
title<-ifelse(sols, 'DataVizA Tutorial: Discriminant Analysis: Solutions','DataVizA Tutorial: Discriminant Analysis')
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
#Use MASS package
library(MASS)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
#Load in New Wine Data
NewWines<-readRDS('NewWines.rds')
ldaout<-lda(BestMarket~.,data = ExistingWines)
yhat_lda<-predict(ldaout,newdata = NewWines)
#The first ten predictions can be checked using the head function
head(yhat_lda$class,10)
#Use MASS package
library(MASS)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
#Load in New Wine Data
NewWines<-readRDS('NewWines.rds')
qdaout<-qda(BestMarket~.,data = ExistingWines)
yhat_qda<-predict(qdaout,newdata = NewWines)
head(yhat_qda$class,10)
head(yhat_lda$posterior,10)
set.seed(1983)
#Create an indicator that determines whether it is training or test sample.
ind<-ifelse(runif(125)<0.7,"Training Sample","Test Sample")
#A data set augmented with sample information
Data_with_Sample<-add_column(ExistingWines,Sample=ind)
View(Data_with_Sample)
#rmarkdown::render('DA.Rmd',output_file='DA.pdf')
#rmarkdown::render('DA.Rmd',output_file='DASols.pdf')
sols<-TRUE
title<-ifelse(sols, 'DataVizA Tutorial: Discriminant Analysis: Solutions','DataVizA Tutorial: Discriminant Analysis')
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
#Use MASS package
library(MASS)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
#Load in New Wine Data
NewWines<-readRDS('NewWines.rds')
ldaout<-lda(BestMarket~.,data = ExistingWines)
yhat_lda<-predict(ldaout,newdata = NewWines)
#The first ten predictions can be checked using the head function
head(yhat_lda$class,10)
#Use MASS package
library(MASS)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
#Load in New Wine Data
NewWines<-readRDS('NewWines.rds')
qdaout<-qda(BestMarket~.,data = ExistingWines)
yhat_qda<-predict(qdaout,newdata = NewWines)
head(yhat_qda$class,10)
head(yhat_lda$posterior,10)
set.seed(1983)
ldaout<-lda(BestMarket~.,data = train_data)
library(dplyr)
#Create an indicator that determines whether it is training or test sample.
ind<-ifelse(runif(125)<0.7,"Training Sample","Test Sample")
#A data set augmented with sample information
Data_with_Sample<-add_column(ExistingWines,Sample=ind)
train_data<-Data_with_Sample%>%
filter(Sample=="Training Sample")%>%
select(-Sample)
test_data<-Data_with_Sample%>%
filter(Sample=="Test Sample")%>%
select(-Sample)
ldaout<-lda(BestMarket~.,data = train_data)
yhat_lda<-predict(ldaout,newdata = test_data)
mean(yhat_lda$class!=test_data$BestMarket)
qdaout<-qda(BestMarket~.,data = train_data)
yhat_qda<-predict(qdaout,newdata = test_data)
mean(yhat_qda$class!=test_data$BestMarket)
#For this particular example XXX has a lower missclassification rate
yhat_qda$posterior
yhat_qda$posterior%>%head(5)
yhat_lda$posterior%>%head(5)
ExistingWines%>%
filter(BestMarket=='Australia')%>%
select_if(is.numeric)%>%
cov
#QDA is better if the variance covariance matrices are different for
#different groups
#Covariance for wines suited to Australia
ExistingWines%>%
filter(BestMarket=='Australia')%>%
select_if(is.numeric)%>%
cov->cov_Aus
#Covariance for wines suited to Europe
ExistingWines%>%
filter(BestMarket=='Europe')%>%
select_if(is.numeric)%>%
cov->cov_Eur
#Covariance for wines suited to Japan
ExistingWines%>%
filter(BestMarket=='Japan')%>%
select_if(is.numeric)%>%
cov->cov_Jap
View(cov_Aus)
View(cov_Jap)
View(cov_Eur)
heatmap(cov_Aus)
heatmap(cov_Aus)
plot()
new.plot()
dev.off()
heatmap(cov_Aus)
?heatmap
image(cov_Aus)
image(t(cov_Aus))
image(cov_Aus[13:1,])
heatmap(cov_Aus)
image(cov_Aus)
ExistingWines%>%
filter(BestMarket=='Australia')%>%
select_if(is.numeric)%>%
cor->cov_Aus
image(cov_Aus)
dev.off()
image(cov_Aus)
ExistingWines%>%
filter(BestMarket=='Europe')%>%
select_if(is.numeric)%>%
cor->cov_Eur
ExistingWines%>%
filter(BestMarket=='Japan')%>%
select_if(is.numeric)%>%
cor->cov_Jap
image(cov_Aus)
image(cov_Eur)
image(cov_Jap)
ExistingWines%>%
group_by(BestMarket)%>%
summarise(var)
ExistingWines%>%
group_by(BestMarket)%>%
summarise_all(var)
ExistingWines%>%
group_by(BestMarket)%>%
summarise_all(var)%>%
print
ExistingWines%>%
group_by(BestMarket)%>%
summarise_all(var)-?a
ExistingWines%>%
group_by(BestMarket)%>%
summarise_all(var)->a
a
?skew
??skew
#Both LDA and QDA are only optimal under normality
library(tidyr)
ExistingWines%>%
gather(key = Variable, value = Val,-BestMarket)%>%View
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
ggplot(aes(x=Value,col=BestMarket))+geom_density()+facet_wrap(~Variable,4,3)
#Both LDA and QDA are only optimal under normality
library(tidyr)
library(ggplot2)
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
ggplot(aes(x=Value,col=BestMarket))+geom_density()+facet_wrap(~Variable,4,3)
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
ggplot(aes(x=Value,col=BestMarket))+geom_density()+facet_wrap(~Variable,nrow = 4)
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
ggplot(aes(x=Value,col=BestMarket,group=Variable))+geom_density()+facet_wrap(~Variable,nrow = 4)
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
filter(Variable=='Alcohol')
ggplot(aes(x=Value,col=BestMarket))+geom_density()
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
filter(Variable=='Alcohol')%>%
ggplot(aes(x=Value,col=BestMarket))+geom_density()
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
ggplot(aes(x=Value,col=BestMarket))+geom_density()+facet_wrap(~Variable,nrow = 4)
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
ggplot(aes(x=Value,col=BestMarket))+geom_density()+facet_wrap(~Variable,nrow = 4,scales = 'free_x')
ExistingWines%>%
gather(key = Variable, value = Value,-BestMarket)%>%
ggplot(aes(x=Value,col=BestMarket))+geom_density()+facet_wrap(~Variable,nrow = 4,scales = 'free')
rmarkdown::render('DA.Rmd',output_file='DASols.pdf')
rmarkdown::render('DA.Rmd',output_file='DASols.pdf')
rmarkdown::render('DA.Rmd',output_file='DA.pdf')
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
rmarkdown::render('Predictive.Rmd',output_file='Predictive.pdf')
rmarkdown::render('Predictive.Rmd',output_file='PredictiveSols.pdf')
rmarkdown::render('Predictive.Rmd',output_file='PredictiveSols.pdf')
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
#rmarkdown::render('kNN.Rmd',output_file='kNN.pdf')
#rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
sols<-TRUE
title<-ifelse(sols, 'DataVizA Tutorial: k Nearest Neighbour Classification: Solutions','DataVizA Tutorial: k Nearest Neighbour Classification')
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
#Use tidyverse
library(dplyr)
library(class)
#Load in data
ExistingWines<-readRDS('ExistingWines.rds')
#Split x and y variables and standardise
old_x<-select(ExistingWines,-BestMarket)%>%scale()
#Keep mean and standard deviation
mean_old_x<-attr(old_x,"scaled:center")
std_old_x<-attr(old_x,"scaled:scale")
old_y<-pull(ExistingWines,BestMarket)
#Load in New Wine Data
new_x<-readRDS('NewWines.rds')%>%
scale(center = mean_old_x,scale = std_old_x)
yhat_k1<-knn(old_x,new_x,old_y,k=1)
#The first ten predictions can be checked using the head function
head(yhat_k1,10)
#Same code as before different k argument
yhat_k11<-knn(old_x,new_x,old_y,k=11)
head(yhat_k11,10)
#Same as before but set prob to T
yhat_k11<-knn(old_x,new_x,old_y,k=11,prob = T)
#Use attr function to get probabilities
head(attr(yhat_k11,"prob"),10)
#Notice that only the probability of the highest probabilty class is available.
set.seed(1983)
#Create an indicator that determines whether it is training or test sample.
ind<-ifelse(runif(125)<0.7,"Training Sample","Test Sample")
train_y<-old_y[ind=="Training Sample"]
test_y<-old_y[ind=="Test Sample"]
train_x<-old_x[ind=="Training Sample",]
test_x<-old_x[ind=="Test Sample",]
yhat_k1<-knn(train_x,test_x,train_y,k=1)
mean(yhat_k1!=test_y)
yhat_k11<-knn(train_x,test_x,train_y,k=5)
mean(yhat_k11!=test_y)
rmarkdown::render('kNN.Rmd',output_file='kNNSols.pdf')
rmarkdown::render('kNN.Rmd',output_file='kNN.pdf')
rmarkdown::render('kNN.Rmd',output_file='kNN.pdf')
knitr::opts_chunk$set(echo = TRUE)
rmarkdown::render('MatrixGeometry.Rmd',output_file='MatrixGeometry.pdf')
rmarkdown::render('MatrixGeometry.Rmd',output_file='MatrixGeometrySols.pdf')
0.06*125
NewWines
knitr::opts_chunk$set(echo = TRUE)
require(kableExtra)
require(tibble)
# Tree with minimum 15 observations per bin
tree<-rpart(BestMarket~.,
data = train_data)
rmarkdown::render('Trees.Rmd',output_file='TreesSols.pdf')
rmarkdown::render('Trees.Rmd',output_file='Trees.pdf')
rmarkdown::render('Trees.Rmd',output_file='Trees.pdf')
rmarkdown::render('Trees.Rmd',output_file='TreesSols.pdf')
